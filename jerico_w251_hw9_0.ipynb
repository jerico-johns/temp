{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "#These are DDP specific packages. \n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "#These are AMP (Mixed Precision) specific packages \n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a960f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Weights and Biases package \n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start a W&B run\n",
    "wandb.init(project='hw9', entity='jjohns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88df755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed so we get consistent results. \n",
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf676f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca629f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccc07a",
   "metadata": {},
   "source": [
    "### Set the architecture to resnet 18 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#Set torch architecture to resnet18\n",
    "#ResNet-18 is a convolutional neural network that is 18 layers deep. \n",
    "#You can load a pretrained version of the network trained on more than a million images from the ImageNet database [1]. \n",
    "#The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. \n",
    "#As a result, the network has learned rich feature representations for a wide range of images. \n",
    "#The network has an image input size of 224-by-224. \n",
    "\n",
    "#See here for original paper which provides implementations research team used: https://arxiv.org/pdf/1512.03385.pdf\n",
    "ARCH  = 'resnet18'\n",
    "# please look up how to do that\n",
    "########################\n",
    "#Set our hyperparams \n",
    "#Outer training loop input: How many passes through entire training set we make. If batch size = training size, then epoch = iterations. \n",
    "EPOCHS = 5\n",
    "#Optimizer input: how much to change the model in response to the estimated error each time the model weights are updated\n",
    "LR = 0.1\n",
    "#Optimizer input: momentum is method which helps accelerate gradients vectors in the right directions, thus leading to faster convergence to local/global minima. \n",
    "MOMENTUM = 0.9\n",
    "#Optimizer input: Weight decay is a regularization technique by adding a small penalty, usually the L2 norm of the weights (all the weights of the model), to the loss function. \n",
    "#loss = loss + weight decay parameter * L2 norm of the weights. \n",
    "WEIGHT_DECAY = 0.0001\n",
    "PRINT_FREQ = 256\n",
    "#Batch size for training / validation loss calcs. \n",
    "TRAIN_BATCH=256\n",
    "VAL_BATCH=256\n",
    "#Setting the argument num_workers as a positive integer will turn on multi-process data loading with the specified number of loader worker processes.\n",
    "#For CUDA: we recommend using automatic memory pinning (i.e., setting pin_memory=True), which enables fast data transfer to CUDA-enabled GPUs.\n",
    "WORKERS=4\n",
    "\n",
    "#TODO: Ensure these tie to the VM directories (volume mount for Docker container)\n",
    "TRAINDIR =\"/workspace/storage/train\"\n",
    "VALDIR = \"/workspace/storage/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate wandb with desired fiels \n",
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92528f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Save model inputs and hyperparameters\n",
    "#config = wandb.config\n",
    "#config.learning_rate = LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb445faf",
   "metadata": {},
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available in this cell\n",
    "# if it is not available, you should not go forward!\n",
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "#Assuming this should be tcp://publicipv4:inboundport\n",
    "URL = 'tcp://3.18.105.108:1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(backend = BACKEND, init_method = URL, world_size = WORLD_SIZE, rank = RANK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f18bca",
   "metadata": {},
   "source": [
    "### Assign your GPU below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your GPU in this cell(they are zero indexed) (Must match RANK)\n",
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "torch.cuda.set_device(RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable algorithm optimization\n",
    "#benchmark mode is good whenever your input sizes for your network do not vary. This way, cudnn will look for the optimal set of algorithms for that particular configuration (hardware + input) (which takes some time). This usually leads to faster runtime.\n",
    "#But if your input sizes changes at each iteration, then cudnn will benchmark every time a new size appears, possibly leading to worse runtime performances.\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51bd3c",
   "metadata": {},
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    #AverageMeter: Computes and stores the average and current value.\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    #Show ProgressMeter\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "    \n",
    "    #Instantiate GradSCaler() for AMP\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    ######################\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "    ################\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        # send the images to cuda device\n",
    "        # send the target to cuda device\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        #Compute output with quantization (AMP)\n",
    "        with autocast(): \n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # compute output\n",
    "        #output = model(images)\n",
    "        # output = model ?? images\n",
    "        \n",
    "\n",
    "        # compute loss \n",
    "        # loss = criterion, output, target\n",
    "        #loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #topk accuracy counts a model as being accurate if the correct result is in the top n predicted class probabilities (i.e. may not be the prediction)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        #Use AverageMeter().update to update the averages \n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        #First need to zero out gradient to prevent \"exploding gradient\" problem. \n",
    "        #Default is to sum or accumulate losses on backward passes (loss.backward()) bc it's convient for RNN. \n",
    "        optimizer.zero_grad()\n",
    "        #Backprop: Computes gradient (dloss/dx) for every parameter x which has requires_grad = True. These are accumulated into x.grad for every parameter x. \n",
    "        #x.grad += dloss/dx   -->  x += -lr * x.grad\n",
    "        loss.backward()\n",
    "        #Update paremeters (weights) based on previous step\n",
    "        optimizer.step()\n",
    "    \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274eed2d",
   "metadata": {},
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            \n",
    "            ### send the images and target to cuda\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "\n",
    "            # compute output\n",
    "            # output = model ??? images?\n",
    "            output = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            # loss  = criterion ?? output ?? target\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "        \n",
    "    wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d63efc",
   "metadata": {},
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0424cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    # state ??? \n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63906c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are adjusting the LR manually use this\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    #Adjusting learning drop from 30 to 20 \n",
    "    lr = LR * (0.1 ** (epoch // 20))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97589350",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]\n",
    "#Adjusting resnet normalizations here\n",
    "resnet_mean_RGB = [0.485, 0.456, 0.406]\n",
    "resnet_std_RGB = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting transforms with updated normalizations here (for Resnet18)\n",
    "#Link: https://pytorch.org/vision/stable/models.html\n",
    "normalize = transforms.Normalize(mean=resnet_mean_RGB, std=resnet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Determine which IMG_SIZE we need\n",
    "#IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e08c1",
   "metadata": {},
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ce504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the model\n",
    "# model = ... \n",
    "#TODO: Determine how many classes we need \n",
    "NUM_CLASSES = 1000\n",
    "\n",
    "model = models.__dict__[ARCH]()\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the model to the cuda device.. \n",
    "model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap model in DDP class for distributed processing across 2 VMs\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f38bc1",
   "metadata": {},
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55948c9f",
   "metadata": {},
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41495315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df25bd",
   "metadata": {},
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd70ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/optim.html\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See here for these steps: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "transform_train = transforms.Compose([\n",
    "    #Adjusting crop call and size\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(resnet_mean_RGB, resnet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c0686",
   "metadata": {},
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae103ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/49073799/pytorch-testing-with-torchvision-datasets-imagefolder-and-dataloader\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ad5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(resnet_mean_RGB, resnet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95faca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793c534",
   "metadata": {},
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, \n",
    "        sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e271e0",
   "metadata": {},
   "source": [
    "### Create the c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ee261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    #See here for more: https://stackoverflow.com/questions/48324152/pytorch-how-to-change-the-learning-rate-of-an-optimizer-at-any-given-moment-no\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    \n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    #Adjusting by switching to manual scheduler (adjust_learning_rate)\n",
    "    #scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    # 3. Log metrics over time to visualize performance\n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
